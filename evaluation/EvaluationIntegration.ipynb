{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluation\n",
    "\n",
    "This notebook is used to evaluate the Soft Query Evaluation System. \n"
   ],
   "id": "3ed340c691f0a68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To evaluate the soft query evaluation system we create queries, encoded as evaluation plans, and execute them on a [hand-crafted schema](https://github.com/HackerBschor/SofteningQueryEvaluation/blob/main/evaluation/schema.json).\n",
    "The queries result set $R$ is then compared against the ground truth set $G$ to determine the true positives $TPs = R \\cap G$, the false positives $FPs = R \\setminus G$ and the false negatives $FNs = G \\setminus R$. Using these sets, we can calculate the following metrics:\n",
    "1) Precision: $\\frac{|TP|}{|TP| + |FP|}$\n",
    "2) Recall: $\\frac{|TP|}{|TP| + |FN|}$\n",
    "3) F1: $\\frac{2 \\cdot Precision \\cdot Recall}{Precision + Recall}$\n",
    "4) Jaccard-Coefficient: $\\frac{|TP|}{|G \\cup R|}$\n",
    "\n",
    "Furthermore, we collect the runtime, to compare it with the execution time of a query that replaces all soft bindings with strict bindings and therefore, doesn't utilize LLMs.\n",
    "\n",
    "### Evaluation Schema\n",
    "\n",
    "The schema is created to maximize **Cross-Domain Generalization**, in order to simulate a real world application of the software.\n",
    "Therefore, we include data from different domains such as:\n",
    "1) Medicine\n",
    "2) Chemistry\n",
    "3) E-Commerce & Retail\n",
    "4) Social Media & User-Generated Content\n",
    "5) Geography\n",
    "6) Entertainment & Media (Movies/ Music)\n",
    "7) Sports & Gaming\n",
    "\n",
    "\n",
    "### Test Criteria\n",
    "We identified 8 different test criteria, where the usage of soft bindings can benefit the final result. We try to involve all test criteria in every domain to maximize the significance for every domain.\n",
    "We define the test criteria as follows:\n",
    "1) Semantic Matching ('Movie about toys that come to life' $\\rightarrow$ Record of 'Toy Story')\n",
    "2) Lexical & Contextual Ambiguity ('Apple' $\\rightarrow$ 'Company', 'Apple' $\\rightarrow$ 'Fruit')\n",
    "3) Spelling Variations & Typos ('Aple' $\\rightarrow$ 'Apple', 'Neighbour' $\\rightarrow$ 'Neighbor')\n",
    "4) Synonyms & Conceptual Overlap ('High Blood Pressure' $\\approx$ 'Hypertension', 'Laptop' $\\approx$ 'Notebook')\n",
    "5) Aliases ('Lady Gaga' $\\approx$ 'Stefani Joanne Angelina Germanotta', 'J. Smith' $\\approx$ 'Jane Smith')\n",
    "6) Abbreviations & Acronyms ('NYC' $\\approx$ 'New York City', 'Dr' $\\approx$ 'Doctor', 'AI' $\\approx$ 'Artificial Intelligence')\n",
    "7) Different Languages (Apple $\\approx$ Apfel $\\approx$ Mela)\n",
    "8) Unit & Format Inconsistencies ('2007-06-29' $\\approx$ '06/29/2007' $\\approx$ 'June 29, 2007' $\\approx$ '29.06.2007' $\\approx$ '29. Juni 2007', '2.2 lbs' $\\approx$ '1 kg', '1M' $\\approx$ '1.000.000' $\\approx$ 1000000)\n",
    "\n",
    "The defined test criteria mostly tests for semantic equality $\\approx$. However, a database also offers operators like $<$, $>$, $!=$.\n",
    "So, if applicable, we also include range queries and queries for semantic inequality. These range queries are mostly affect the criteria `Unit & Format Inconsistencies`."
   ],
   "id": "a1e178c1d3d54865"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Import & Initialize: Models, Data and Functions"
   ],
   "id": "8ffe1df7f4d19243"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:30:55.976758Z",
     "start_time": "2025-02-09T13:30:55.973757Z"
    }
   },
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import DBSCAN, SpectralClustering\n",
    "\n",
    "from db.criteria import *\n",
    "from db.operators import *\n",
    "from db.operators.Aggregate import *\n",
    "from db.structure import *\n",
    "\n",
    "from models.embedding import SentenceTransformerEmbeddingModel\n",
    "from models.semantic_validation import LLaMAValidationModel\n",
    "from models.text_generation.LLaMA import LLaMATextGenerationModel\n",
    "\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_dummy_operators():\n",
    "    with open(\"schema.json\", \"r\", encoding=\"UTF-8\") as schema:\n",
    "        schema = json.load(schema)\n",
    "\n",
    "    operators = {}\n",
    "    for relation, data in schema.items():\n",
    "        operators[relation] = Dummy(relation, [x[\"name\"] for x in data[\"schema\"]], data[\"data\"])\n",
    "    return operators\n"
   ],
   "id": "8526818f98ef2e14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate(op, result_cols, gt):\n",
    "    st = time.time()\n",
    "    op.open()\n",
    "    result = {(row[col] for col in result_cols) for row in op}\n",
    "    exec_time = time.time() - st\n",
    "    \n",
    "    tps, fns, fps = gt & result, gt - result, result - gt\n",
    "    tp, fn, fp = len(tps), len(fns), len(fps)\n",
    "    precision = round((tp / (tp + fp) if (tp + fp) > 0 else 0) * 100.0)\n",
    "    recall = round((tp / (tp + fn) if (tp + fn) > 0 else 0) * 100.0)\n",
    "    f1_score = round(((2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0))\n",
    "    jaccard_coefficient = len(tps) / len(gt | result)\n",
    "    print(\"False Positives:\", \"\\n\".join(map(lambda x: f\"\\t{x}\", fps)), \"\", sep=\"\\n\")\n",
    "    print(\"False Negatives:\", \"\\n\".join(map(lambda x: f\"\\t{x}\", fns)), \"\", sep=\"\\n\")\n",
    "    return {\n",
    "        \"precision\": precision, \n",
    "        \"recall\": recall, \n",
    "        \"f1_score\": f1_score, \n",
    "        \"jaccard_coefficient\": jaccard_coefficient,\n",
    "        \"exec_time\": exec_time\n",
    "    }"
   ],
   "id": "802bc3e6332f0087",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load Models\n",
    "mm = ModelMgr(config=\"../config.ini\")\n",
    "em = SentenceTransformerEmbeddingModel(mm)\n",
    "sv = LLaMAValidationModel(mm, temperature=0.0001)\n",
    "gm = LLaMATextGenerationModel(mm)\n",
    "\n",
    "# Load Data\n",
    "ops = load_dummy_operators()"
   ],
   "id": "9051408c8aad6e64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Test Case 1\n",
    "\n",
    "### Find disease where symptoms match description (Semantic Matching)\n",
    "\n",
    "$$ \n",
    "\\sigma_{\\text{symptoms}  \\approx  \\text{'<description>'} } (\\bowtie_{\\text{disease}}(\\text{Diseases}, \\gamma_{\\text{disease}, STR\\_AGG(\\text{symptom}) \\rightarrow \\text{symptoms} } (\\text{Symptoms}))) \n",
    "$$\n",
    "\n",
    "### 1.2: Find disease where all symptoms occur (Spelling Variations: e.g. 'high fefer' $\\approx$ 'high fever'; Synonyms & Conceptual Overlap: 'Appetite suppression' $\\approx$ 'loss of appetite')\n",
    "\n",
    "$$ \n",
    "    \\sigma_{\\text{number\\_symptoms} > 3} (\n",
    "        \\gamma_{\\text{disease}, \\text{COUNT(Symptom)} \\rightarrow \\text{number\\_symptoms}} (\\sigma_{\\text{description} \\approx \\text{<symptom 2>} \\lor \\text{description} \\approx \\text{<symptom 2>} \\lor \\text{description} \\approx \\text{<symptom 3>}}(\\text{Symptoms}))\n",
    "    )\n",
    "$$\n"
   ],
   "id": "7e2427378fa9d269"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO",
   "id": "f2546b0440068c63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Test Case 2: Chemistry\n",
    "### 2.1: Find Organic Chemicals (Semantic Matching)\n",
    "$$\n",
    "\\sigma_{$\\approx$ \\text{'Is organic'}}(\\text{Chemicals})\n",
    "$$"
   ],
   "id": "f645e97184f5c258"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO",
   "id": "f14837f54e3c45c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2. Find all warnings to the chemicals (Synonyms: 'Drinking Alcohol' $\\approx$ 'CH3OH' $\\approx$ 'Ethanol')\n",
    "\n",
    "$$\n",
    "\\bowtie_{\\text{scientific\\_name} \\approx \\text{chemical\\_name}} (\\text{Chemicals}, \\gamma_{\\text{chemical\\_name}, STR\\_AGG(\\text{warning}) \\rightarrow \\text{warning\\_list} } (\\text{Chemical Warnings}))\n",
    "$$"
   ],
   "id": "c8ca7ee5451e0782"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "gt1_2 = {(\"H2O\", \"Water\"), (\"H2SO4\", \"Sulfuric Acid\"), (\"CH3OH\", \"Methanol\"), (\"HCl\", \"Hydrochloric Acid\"), (\"NH3\", \"Ammonia\"), (\"C2H5OH\", \"Ethanol\"), (\"C6H6\", \"Benzene\"), (\"Cl2\", \"Chlorine\"), (\"C3H6O\", \"Acetone\"), (\"NaOH\", \"Sodium Hydroxide\"), (\"C8H10N4O2\", \"Caffeine\")}\n",
    "\n",
    "op1_2_hard = InnerHashJoin(ops[\"chemicals\"], ops[\"chemical_warnings\"],  Column(\"scientific_name\"), Column(\"name\"))\n",
    "evaluate(op1_2_hard, [\"scientific_name\", \"name\"], gt1_2)\n",
    "\n",
    "op1_2_soft = InnerSoftJoin(\n",
    "    ops[\"chemicals\"], ops[\"chemical_warnings\"],\n",
    "    Column(\"scientific_name\"), Column(\"name\"),\n",
    "    em=em, sv=sv, threshold=0.3, use_semantic_validation=True, sv_template=\"Is {scientific_name} the scientific name for {name}\")\n",
    "\n",
    "evaluate(op1_2_soft, [\"scientific_name\", \"name\"], gt1_2)"
   ],
   "id": "bcd202448c093edf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.3: Find the chemical: (Spelling Variations & Typos: 'Etanol' $\\approx$ 'Ethanol'; Languages: 'Hydrochloric Acid' $\\approx$ 'Salzsäure')\n",
    "* $ \\sigma_{\\text{chemical\\_name} \\approx 'Wtaer'}(\\text{Chemical Warnings}) $ $\\rightarrow$ Water\n",
    "* $ \\sigma_{\\text{chemical\\_name} \\approx 'Sulfric Aciid'}(\\text{Chemical Warnings}) $ $\\rightarrow$ Sulfuric Acid\n",
    "* $ \\sigma_{\\text{chemical\\_name} \\approx 'Methonol'}(\\text{Chemical Warnings}) $  $\\rightarrow$ Methanol\n",
    "* $ \\sigma_{\\text{chemical\\_name} \\approx 'Hydrocloric Acd'}(\\text{Chemical Warnings}) $ $\\rightarrow$ Hydrochloric Acid\n",
    "* $ \\sigma_{\\text{chemical\\_name} \\approx 'Muratic Acd'}(\\text{Chemical Warnings}) $ $\\rightarrow $ Muriatic Acid\n",
    "* $ \\sigma_{\\text{chemical\\_name} \\approx 'Amnoia'}(\\text{Chemical Warnings}) $ $\\rightarrow$ Ammonia\n",
    "* $ \\sigma_{\\text{chemical\\_name} \\approx 'Ethonol'}(\\text{Chemical Warnings}) $ $\\rightarrow$ Ethanol\n",
    "* $ \\sigma_{\\text{chemical\\_name} \\approx 'Driniking Alcohal'}(\\text{Chemical Warnings}) $ $\\rightarrow$ Drinking Alcohol\n",
    "* $ \\sigma_{\\text{chemical\\_name} \\approx 'Benzne'}(\\text{Chemical Warnings}) $ $\\rightarrow$ Benzene\n",
    "* $ \\sigma_{\\text{chemical\\_name} \\approx 'Clorine'}(\\text{Chemical Warnings}) $ $\\rightarrow$ Chlorine\n",
    "* $ \\sigma_{\\text{chemical\\_name} \\approx 'Acetne'}(\\text{Chemical Warnings}) $ $\\rightarrow$ Acetone\n",
    "* $ \\sigma_{\\text{chemical\\_name} \\approx 'Soduim Hydrxoide'}(\\text{Chemical Warnings}) $ $\\rightarrow$ Sodium Hydroxide\n",
    "* $ \\sigma_{\\text{chemical\\_name} \\approx 'Caffiene'}(\\text{Chemical Warnings}) $ \\rightarrow Caffeine\n",
    "* $\\sigma_{\\text{chemical\\_name} \\approx 'Salzsäure'}(\\text{Chemical Warnings})$ $\\rightarrow$ Hydrochloric Acid\n",
    "* $\\sigma_{\\text{chemical\\_name} \\approx '盐酸'}(\\text{Chemical Warnings})$ $\\rightarrow$ Hydrochloric Acid\n",
    "* $\\sigma_{\\text{chemical\\_name} \\approx 'Acido cloridrico'}(\\text{Chemical Warnings})$ $\\rightarrow$ Hydrochloric Acid\n",
    "* $\\sigma_{\\text{chemical\\_name} \\approx 'Соляная кислота'}(\\text{Chemical Warnings})$ $\\rightarrow$ Hydrochloric Acid\n",
    "* $\\sigma_{\\text{chemical\\_name} \\approx 'Eau'}(\\text{Chemical Warnings})$ $\\rightarrow$ Water\n",
    "* $\\sigma_{\\text{chemical\\_name} \\approx '水'}(\\text{Chemical Warnings})$ $\\rightarrow$ Water\n",
    "* $\\sigma_{\\text{chemical\\_name} \\approx 'вода'}(\\text{Chemical Warnings})$ $\\rightarrow$ Water\n",
    "* $\\sigma_{\\text{chemical\\_name} \\approx 'Wasser'}(\\text{Chemical Warnings})$ $\\rightarrow$ Water\n",
    "* $\\sigma_{\\text{chemical\\_name} \\approx 'Eau'}(\\text{Chemical Warnings})$ $\\rightarrow$ Water\n",
    "\n",
    "\n",
    "### 2.4: Find Acronyms: (Acronyms: H $\\approx$ Hydrogen, He $\\approx$ Helium)\n",
    "\n",
    "$$\n",
    "\\bowtie_{\\text{element} \\approx \\text{symbol}} (\\text{Elements}, \\text{ElementPhases})\n",
    "$$\n",
    "\n",
    "### 2.5: Find p.H. neutral chemicals (Unit & Format Inconsistencies: p.H. = 7.0 $\\approx$ 'Neutral')\n",
    "\n",
    "$$ \n",
    "\\sigma_{\\text{ph}\\approx\\text{'Neutral'}} (\\text{Chemicals})\n",
    "$$"
   ],
   "id": "611651fed45c9f79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO",
   "id": "135d0eeaf6df3f1b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test Case 3: E-Commerce & Retail",
   "id": "e8c9860cbee7d58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.1. Match companies from two datasets (Semantic Matching: {\"name\": \"microsoft\", \"year_founded\": 1975, \"domain\": \"computer software\" ... } $\\approx$ {...})",
   "id": "3b9466d667f867ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test Case 4: Social Media & User-Generated Content",
   "id": "903b09b43bfa49ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Test Case 5: Geography\n",
    "### 7.2. Spelling Variations & Typos, 7.3. Synonyms & Conceptual Overlap \n",
    "\n",
    "\n",
    "### 7.5. Join two country datasets: (Abbreviations & Acronyms, Different Languages: 'AT' $\\approx$ 'Österreich', 'EE' $\\approx$ 'Estonia'\n"
   ],
   "id": "7329809a0766c891"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# TODO",
   "id": "4b691c4a15bb9cb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Test Case 6: Entertainment & Media (Movies/ Music\n",
    "### 6.1 Search Movies base don release disjunction (Unit & Format Inconsistencies: 'Before 2000' $\\approx$ '1999')"
   ],
   "id": "d0473afad358bf87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "gt6_1 = {(\"Pirates of the Caribbean: Dead Man's Chest\", ), (\"Charlie and the Chocolate Factory\", ), (\"Inception\", ), (\"The Matrix\", )}",
   "id": "dfa9fc65d3602a0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "crit1 = SoftEqual(Column(\"release\"), Constant(\"2006\"), em=em, threshold=0.5)\n",
    "crit2 = SoftEqual(Column(\"release\"), Constant(\"July\"), em=em, threshold=0.5)\n",
    "crit3 = SoftEqual(Column(\"release\"), Constant(\"Before 2000\"), em=em, threshold=0.5)\n",
    "op6_1 = Select(ops[\"movies\"], DisjunctiveCriteria([crit1, crit2, crit3]))\n",
    "evaluate(op6_1, [\"name\"], gt6_1)"
   ],
   "id": "e66ffdb8ac2fb9c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# op6_1 = Select(ops[\"movies\"], SoftValidate(\"Is {release} in 2006 or is {release} in July or is {release} before 2000?\", sv=sv, full_record=False))\n",
    "# crit11 = SoftValidate(\"Is {release} in 2006?\", sv=sv, full_record=False)\n",
    "# crit22 = SoftValidate(\"Is {release} in July?\", sv=sv, full_record=False)\n",
    "# crit33 = SoftValidate(\"Is {release} before 2000?\", sv=sv, full_record=False)\n",
    "# op = Select(ops[\"movies\"], DisjunctiveCriteria([crit11, crit22, crit33]))\n",
    "\n",
    "# result2_2 = {(x[\"name\"], ) for x in op}\n",
    "# evaluate(gt2_1, result2_2)"
   ],
   "id": "a08b819170498007",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.2 Match English and German Moview (Entity Matching, Different Languages)",
   "id": "d350e30dad1c6cf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gt6_2 = {\n",
    "    ('The Lord of the Rings: The Fellowship of the Ring', 'Der Herr der Ringe: Die Gefährten'),\n",
    "    (\"Pirates of the Caribbean: Dead Man's Chest\", 'Pirates of the Caribbean – Fluch der Karibik 2'),\n",
    "    ('The Lord of the Rings: The Return of the King', 'Der Herr der Ringe: Die Rückkehr des Königs'),\n",
    "    ('Charlie and the Chocolate Factory', 'Charlie und die Schokoladenfabrik'),\n",
    "    ('Inception', 'Inception'),\n",
    "    ('The Matrix', 'Matrix')\n",
    "}"
   ],
   "id": "c5aa215084b8b6c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# op6_2 = {(x[\"movies.name\"], x[\"movies_de.name\"]) for x in InnerSoftJoin(ops[\"movies\"], ops[\"movies_de\"], Column(\"movies.name\"), Column(\"movies_de.name\"), em=em, threshold=0.4)}\n",
    "op6_2 = InnerSoftJoin(ops[\"movies\"], ops[\"movies_de\"], None, None, em=em, threshold=0.6)\n",
    "evaluate(op6_2, [\"movies.name\", \"movies_de.name\"],gt6_2)"
   ],
   "id": "9a296b99469b585b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.3 Find Actors (Aliases: 'Orlando Bloom' $\\approx$ '@orlandobloom'; Synonyms & Conceptual Overlap: 'Leonardo DiCaprio $ \\approx $ 'Jack Dawson in Titanic')",
   "id": "fff83ac901c70b18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gt6_4 =  {\n",
    "  ('Carrie-Anne Moss', 'Carrie-Anne Moss'),\n",
    "  ('Elijah Wood', 'Elijah Jordan Wood'),\n",
    "  ('Elijah Wood', 'Elijah Wood'),\n",
    "  ('Elliot Page', 'Elliot Page'),\n",
    "  ('Freddie Highmore', 'Alfred Highmore'),\n",
    "  ('Ian McKellen', 'Sir Ian Murray McKellen'),\n",
    "  ('Johnny Depp', 'John Christopher \"Johnny\" Depp II'),\n",
    "  ('Johnny Depp', 'John Christopher Depp II'),\n",
    "  ('Johnny Depp', 'The Mad Hatter in Alice in Wonderland Actor'),\n",
    "  ('Joseph Gordon-Levitt', 'Joseph Gordon-Levitt'),\n",
    "  ('Keanu Reeves', 'Keanu Charles Reeves'),\n",
    "  ('Keira Knightley', 'Keira Christina Knightley'),\n",
    "  ('Keira Knightley', 'Keira Knightley'),\n",
    "  ('Laurence Fishburne', 'Laurence Fishburne'),\n",
    "  ('Leonardo DiCaprio', 'Jack Dawson in Titanic'),\n",
    "  ('Orlando Bloom', '@orlandobloom'),\n",
    "  ('Orlando Bloom', 'Orlando Bloom'),\n",
    "  ('Orlando Bloom', 'Orlando Jonathan Blanchard Copeland Bloom'),\n",
    "  ('Viggo Mortensen', 'Viggo Mortensen')\n",
    "}"
   ],
   "id": "c206fac4945a527b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "op6_4 = InnerSoftJoin(ops[\"actors\"], ops[\"plays_in\"], Column(\"name\"), Column(\"actor/actress\"), threshold=0.7, em=em)\n",
    "evaluate(op6_4, [\"name\", \"actor/actress\"], gt6_4)"
   ],
   "id": "5aa6cbe6f873c258",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Test Unit & Format Inconsistencies: 06/24/2003 $\\approx$ 24.06.2003, 6/24/2005 > 24.06.2003, 2.2 lbs' $\\approx$ '1 kg\n",
    "\n",
    "* $ \\sigma_{date \\approx '06/24/2003'} (Orders) $\n",
    "* $ \\sigma_{date \\approx '06/24/2003'} (Orders) $\n",
    "* $ \\sigma_{date \\approx '06/24/2003'} (Orders) $\n",
    "* $ \\sigma_{date \\approx '06/24/2003'} (Orders) $\n",
    "* $ \\sigma_{date \\approx '06/24/2003'} (Orders) $\n",
    "* $ \\sigma_{date \\approx '06/24/2003'} (Orders) $\n",
    "* $ \\sigma_{date \\approx '06/24/2003'} (Orders) $\n"
   ],
   "id": "9d42bf80de9f5fdc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Further Experiments\n",
    "## Soft Aggregation"
   ],
   "id": "bb2c2a0dcc648d06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = SoftAggregateFaissKMeans(ops[\"movies\"], [\"name\"], [StringAggregation(\"name\", \"movies\")], em=em, num_clusters=5)\n",
    "print([a for a in x])"
   ],
   "id": "2815442aa9c31d85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = SoftAggregateScikit(ops[\"movies\"], [\"name\"], [StringAggregation(\"name\", \"movies\")], em=em, cluster_class=DBSCAN, cluster_params={\"eps\":3, \"min_samples\": 2})\n",
    "print([a for a in x])"
   ],
   "id": "894780aff1c68315",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = SoftAggregateScikit(ops[\"movies\"], [\"name\"], [CountAggregation(\"name\", \"movies\")], em=em, cluster_class=SpectralClustering, cluster_params={\"n_clusters\": 5, \"assign_labels\" :'discretize', \"random_state\": 0})\n",
    "print([a for a in x])"
   ],
   "id": "95c3d63d0b8cac71",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
